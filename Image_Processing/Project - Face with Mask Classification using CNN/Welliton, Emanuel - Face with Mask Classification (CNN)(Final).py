# -*- coding: utf-8 -*-
"""FULLfacemaskRcgntCNN4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ZhUxw3kQJ-ykMIl4boho94glNYwYH6n
"""

import tensorflow as tf #rede neural
import glob, os, fnmatch # manipular os arquivos
import numpy as np
import matplotlib.pyplot as plt
import random
from tensorflow.keras import layers, models, regularizers
from skimage import io, transform
from skimage.transform import rescale, resize
from PIL import Image

from google.colab import drive
drive.mount("/content/drive/")

path1 = "/content/drive/My Drive/Full Dataset/Train"
path2 = "/content/drive/My Drive/Full Dataset/Test"

c1 = os.listdir(path1)
c2 = os.listdir(path2)

exttrain = []
exttest = []

for e in c1:
    #a = [os.path.splitext(e)[1]]
    if fnmatch.fnmatch(e, '*.png'):
        exttrain.append(1)
    else:
        exttrain.append(0)

for e in c2:
    #a = [os.path.splitext(e)[1]]
    if fnmatch.fnmatch(e, '*.png'):
        exttest.append(1)
    else:
        exttest.append(0)

print(exttest)

len(exttest)

img_train= []
img_test = []

"""# Armazenando todas as Imagens de Treino"""

for filename in glob.glob(path1 + '/*.jpg'):
    print(filename)
    img = io.imread(filename)                
    resized = resize(img, (300,300,3))
    img_train.append(resized)

for filename in glob.glob(path1 + '/*.png'):
    print(filename)
    img = io.imread(filename)                
    resized = resize(img, (300,300,3))
    img_train.append(resized)

len(img_train)

plt.imshow(img_train[20])

"""# Armazenando todas as Imagens de Teste"""

for filename in glob.glob(path2 + '/*.jpg'):
    print(filename)
    img2 = io.imread(filename)                
    resized2 = resize(img2, (300,300,3))
    img_test.append(resized2)

for filename in glob.glob(path2 + '/*.png'):
    print(filename)
    img2 = io.imread(filename)
    resized2 = resize(img2, (300,300,3))
    img_test.append(resized2)

len(img_test)

plt.imshow(img_test[139])

"""# CNN

Total de Imagens = 1400

90% = Treino = 1260

10% = Teste = 140
"""

train_images = np.zeros((1260, 300, 300, 3))
test_images = np.zeros((140, 300, 300, 3))
train_labels = np.zeros((1260, 1))
test_labels = np.zeros((140, 1))

print(train_labels.max())

id_treino = 0
for i in range(len(img_train)):

    train_images[id_treino,:,:,:] = img_train[i]

    if exttrain[i] == 1:
        train_labels[id_treino] = 1
    else:
        train_labels[id_treino] = 0

    id_treino += 1

id_test = 0
for i in range(len(img_test)):

    test_images[id_test,:,:,:] = img_test[i]

    if exttest[i] == 1:
        test_labels[id_test] = 1
    else:
        test_labels[id_test] = 0
        
    id_test += 1

plt.imshow(test_images[1])

#Normalizando os valores do pixels entre 0 e 1
#train_images, test_images = train_images / 255.0, test_images / 255.0

model = models.Sequential()

model.add(layers.Conv2D(32, kernel_size =(3, 3), activation='relu', input_shape = (300, 300, 3))) 
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Conv2D(64, kernel_size = (5, 5), activation='relu'))
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Conv2D(128, kernel_size = (7, 7), activation='relu'))

model.add(layers.Dropout(0.5)) #novo
model.add(layers.Flatten())

model.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))) #adicionado regularizacao
model.add(layers.Dense(2)) #corrigido

model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])

print(model.summary())

history = model.fit(train_images, train_labels, epochs = 50, validation_data=(test_images, test_labels))

plt.figure()
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print(test_acc)

class_names = ['with mask', 'without mask']

#verificar acuracia por classe
import numpy as np
saidas = model.predict(test_images)
labels_out = np.argmax(saidas, axis=1)
pcts = []
for classe in range(0,2):
    indices = np.where(test_labels == classe)[0]
    corretos = np.where(labels_out[indices] == classe)[0]
    porcentagem = len(corretos) / len(indices)
    pcts.append(porcentagem * 100)
    
print('Porcentagens')
for i in range(0,2):
    print('%s -> %.2f %%' %(class_names[i],pcts[i]))